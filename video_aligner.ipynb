{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import lumicks\n",
    "import lumicks.pylake as lk\n",
    "\n",
    "# %matplotlib inline\n",
    "from skimage.transform import rescale\n",
    "import tifffile\n",
    "import os\n",
    "from cv2 import warpAffine, invertAffineTransform\n",
    "from pathlib import Path\n",
    "from cv2 import estimateAffine2D, estimateAffinePartial2D\n",
    "from picasso import io, postprocess\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import argparse\n",
    "import itertools\n",
    "import math\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def norm_image(image, inverse=False):\n",
    "    amin = image.min()\n",
    "    amax = image.max()\n",
    "\n",
    "    if amax != amin:\n",
    "        if inverse:\n",
    "            return 1 - (image - amin) / (amax - amin)\n",
    "        else:\n",
    "            return (image - amin) / (amax - amin)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to test without arguments\n",
    "\n",
    "\n",
    "# irm_path = \"data/20231228-A_IRM_0.5_beads.tif\" #Reference for calculation\n",
    "# wt_path =   \"data/20231228-A_WT_0.5_beads.tif\"\n",
    "\n",
    "irm_path = \"data\\CODE_TEST\\\\20240820-144217_IRM.tiff\"  # Test images\n",
    "wt_path = \"data\\CODE_TEST\\\\20240820-144217_WT.tiff\"\n",
    "bright_path = (\n",
    "    \"video_alignment_data/20240716_Jurkat_20gs_myc/20240716-112826_Bright-field.tif\"\n",
    ")\n",
    "\n",
    "output_path = \"testout/\"\n",
    "\n",
    "\n",
    "align_brightfield = False\n",
    "\n",
    "bf_transform_matrix_file = \"bf_transform_matrix.json\"\n",
    "transform_matrix_file = \"transform_matrix.json\"\n",
    "use_existing_matrix = True  # always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed50d15",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Check if the directory already exists\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322b226",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "irm = lk.ImageStack(irm_path)  # Loading a stack.\n",
    "wt = lk.ImageStack(wt_path)  # Loading a stack.\n",
    "\n",
    "if align_brightfield:\n",
    "    bright_file = lk.ImageStack(bright_path)\n",
    "    bright_g_video = bright_file.get_image(channel=\"green\")\n",
    "    bright_g = bright_g_video[0]\n",
    "    bright_metadata = bright_file._tiff_image_metadata()\n",
    "\n",
    "wt.export_tiff(\n",
    "    output_path + Path(wt_path).stem + \"_aligned.tif\"\n",
    ")  # Save aligned wt stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c011acc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Get channels\n",
    "wt_g_video = wt.get_image(channel=\"green\")\n",
    "irm_g_video = irm.get_image()\n",
    "# wt_r_video = wt.get_image(channel=\"red\")\n",
    "# wt_b_video = wt.get_image(channel=\"blue\")\n",
    "\n",
    "wt_g = wt_g_video[0]\n",
    "irm_g = irm_g_video[0]\n",
    "\n",
    "print(wt_g.shape)\n",
    "plt.imshow(irm_g, alpha=0.5, cmap=\"Blues\")\n",
    "plt.imshow(wt_g, alpha=0.5, cmap=\"Reds\")\n",
    "# plt.imshow(bright_g, alpha=0.5, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(irm_g[0:80, 0:80], alpha=0.5, cmap=\"Blues\")\n",
    "plt.imshow(wt_g[0:80, 0:80], alpha=0.5, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe046734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata\n",
    "\n",
    "wt_metadata = wt._tiff_image_metadata()\n",
    "wt_framerate = wt_metadata[\"Framerate (Hz)\"]\n",
    "wt_roi = wt_metadata[\"Region of interest (x, y, width, height)\"]\n",
    "wt_frame_averaging = wt_metadata[\"Frame averaging\"]\n",
    "print(wt_framerate)\n",
    "\n",
    "irm_metadata = irm._tiff_image_metadata()\n",
    "irm_roi = irm_metadata[\n",
    "    \"Region of interest (x, y, width, height)\"\n",
    "]  # This is different because the wt was prexviously aligned I think. Can this cause issues?\n",
    "irm_framerate = irm_metadata[\"Framerate (Hz)\"]\n",
    "irm_frame_averaging = irm_metadata[\"Frame averaging\"]\n",
    "print(irm_framerate)\n",
    "\n",
    "if align_brightfield:\n",
    "    bright_roi = bright_metadata[\n",
    "        \"Region of interest (x, y, width, height)\"\n",
    "    ]  # This is different because the wt was prexviously aligned I think. Can this cause issues?\n",
    "    bf_framerate = bright_metadata[\"Framerate (Hz)\"]\n",
    "    bf_frame_averaging = bright_metadata[\"Frame averaging\"]\n",
    "    print(bright_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wt_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dce4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "# Pad both images to region of interest\n",
    "padded_wt_filename = Path(wt_path).stem + \"_padded.tif\"\n",
    "wt_g_padded = np.pad(wt_g, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)])\n",
    "# wt_g_padded = wt_g\n",
    "tifffile.imwrite(output_path + padded_wt_filename, wt_g_padded)\n",
    "\n",
    "padded_irm_filename = Path(irm_path).stem + \"_padded.tif\"\n",
    "irm_g_padded = np.pad(irm_g, [(int(irm_roi[1]), 0), (int(irm_roi[0]), 0)])\n",
    "# irm_g_padded = irm_g\n",
    "tifffile.imwrite(output_path + padded_irm_filename, irm_g_padded)\n",
    "\n",
    "if align_brightfield:\n",
    "    padded_bright_filename = Path(bright_path).stem + \"_padded.tif\"\n",
    "    bright_g_padded = np.pad(\n",
    "        bright_g, [(int(bright_roi[1]), 0), (int(bright_roi[0]), 0)]\n",
    "    )\n",
    "\n",
    "    # irm_g_padded = irm_g\n",
    "\n",
    "    # irm_g_padded = np.pad(irm_g, [(int(wt_roi[0]), 0), (int(wt_roi[1]), 0)])\n",
    "\n",
    "    # irm_g_padded = np.pad(irm_g_padded, [(int(wt_roi[0]), 0), (int(wt_roi[1]), 0)])\n",
    "\n",
    "    tifffile.imwrite(output_path + padded_bright_filename, bright_g_padded)\n",
    "\n",
    "\n",
    "# plt.imshow(bright_g_padded, alpha=0.5)\n",
    "\n",
    "\n",
    "ax1.imshow(wt_g_padded, alpha=0.5)\n",
    "# ax1.set_xlim(wt_roi[0], wt_roi[0] + wt_roi[2])\n",
    "# ax1.set_ylim(wt_roi[1], wt_roi[1] + wt_roi[3])\n",
    "\n",
    "ax1.imshow(irm_g_padded, alpha=0.5)\n",
    "# ax1.set_xlim(irm_roi[0], irm_roi[0] + irm_roi[2])\n",
    "# ax1.set_ylim(irm_roi[1], irm_roi[1] + irm_roi[3])\n",
    "\n",
    "\n",
    "# ax1.imshow(bright_g_padded, alpha=0.5)\n",
    "# ax1.set_xlim(bright_roi[0], bright_roi[0] + bright_roi[2])\n",
    "# ax1.set_ylim(bright_roi[1], bright_roi[1] + bright_roi[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"wt_g_video_padded = np.array(\n",
    "    [np.pad(frame, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)]) for frame in wt_g_video]\n",
    ")\n",
    "\n",
    "\n",
    "wt_r_video_padded = np.array(\n",
    "    [np.pad(frame, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)]) for frame in wt_r_video]\n",
    ")\n",
    "wt_b_video_padded = np.array(\n",
    "    [np.pad(frame, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)]) for frame in wt_b_video]\n",
    ")\n",
    "\n",
    "irm_video_padded = np.array(\n",
    "    [\n",
    "        np.pad(frame, [(int(irm_roi[1]), 0), (int(irm_roi[0]), 0)])\n",
    "        for frame in irm_g_video\n",
    "    ]\n",
    ")\n",
    "\n",
    "if align_brightfield:\n",
    "    bf_video_padded = np.array(\n",
    "        [\n",
    "            np.pad(frame, [(int(bf_roi[1]), 0), (int(bf_roi[0]), 0)])\n",
    "            for frame in bf_video\n",
    "        ]\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3204e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b654c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mat = []  # set to empty to check afterwards if I have a matrix\n",
    "bf_transform_mat = []\n",
    "\n",
    "\n",
    "if use_existing_matrix:  # If I have provided a matrix, use that\n",
    "    with open(transform_matrix_file, \"r\") as read_file:\n",
    "        decodedArray = json.load(read_file)\n",
    "        transform_mat = np.asarray(decodedArray[\"transform_matrix\"])\n",
    "        rmsd = decodedArray[\"rmsd\"]\n",
    "        print(transform_mat)\n",
    "    if align_brightfield:\n",
    "        with open(bf_transform_matrix_file, \"r\") as read_file:\n",
    "            decodedArray = json.load(read_file)\n",
    "            bf_transform_mat = np.asarray(decodedArray[\"transform_matrix\"])\n",
    "            print(bf_transform_mat)\n",
    "            rmsd = decodedArray[\"rmsd\"]\n",
    "\n",
    "# manual_x_offset = 327\n",
    "# manual_y_offset = 230\n",
    "\n",
    "# bf_transform_mat[0][2] = bf_transform_mat[0][2] + manual_x_offset\n",
    "# bf_transform_mat[1][2] = bf_transform_mat[1][2] + manual_y_offset\n",
    "# print(bf_transform_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577dcbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irm_framerate)\n",
    "\n",
    "real_irm_framerate = irm_framerate / irm_frame_averaging\n",
    "if align_brightfield:\n",
    "    real_bf_framerate = bf_framerate / bf_frame_averaging\n",
    "real_wt_framerate = wt_framerate / wt_frame_averaging\n",
    "for frame_n, frame in enumerate(wt_g_video):\n",
    "\n",
    "    irm_g_padded_asd = irm_g_video[\n",
    "        round(frame_n * real_irm_framerate / real_wt_framerate)\n",
    "    ]\n",
    "    print(round(frame_n * real_irm_framerate / real_wt_framerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22414c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "irm_warped_video = []\n",
    "bf_warped_video = []\n",
    "wt_video = []\n",
    "\n",
    "\n",
    "if len(transform_mat != 0):  # If I have a matrix either from file or calculated\n",
    "\n",
    "    for frame_n, frame in enumerate(wt_g_video):\n",
    "\n",
    "        irm_g_padded = np.pad(\n",
    "            irm_g_video[round(frame_n * real_irm_framerate / real_wt_framerate)],\n",
    "            [(int(irm_roi[1]), 0), (int(irm_roi[0]), 0)],\n",
    "        )\n",
    "\n",
    "        wt_g_padded = np.pad(frame, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)])\n",
    "        \"\"\"\n",
    "\n",
    "        irm_g_padded = irm_video_padded[\n",
    "            round(frame_n * real_irm_framerate / real_wt_framerate)\n",
    "        ]\n",
    "\n",
    "        wt_g_padded = frame\n",
    "        \"\"\"\n",
    "        irm_g_padded_warped = warpAffine(\n",
    "            irm_g_padded, transform_mat, (wt_g_padded.shape[1], wt_g_padded.shape[0])\n",
    "        )\n",
    "\n",
    "        # This hack is done to reduce the total contrast in the resulting image\n",
    "\n",
    "        # Otherwise, the 0s make it hard to see\n",
    "\n",
    "        irm_g_padded_warped[irm_g_padded_warped <= np.amin(irm_g_padded)] = np.mean(\n",
    "            irm_g_padded\n",
    "        )\n",
    "\n",
    "        irm_g_padded_warped = norm_image(irm_g_padded_warped, False)\n",
    "\n",
    "        wt_g_padded = norm_image(wt_g_padded)\n",
    "\n",
    "        wt_video.append(wt_g_padded)\n",
    "\n",
    "        irm_warped_video.append(irm_g_padded_warped)\n",
    "\n",
    "        if align_brightfield:\n",
    "            if len(bf_transform_mat) != 0:\n",
    "                bf_g_padded = bright_g_video[\n",
    "                    round(frame_n * real_bf_framerate / real_wt_framerate)\n",
    "                ]\n",
    "\n",
    "                bf_g_padded_warped = warpAffine(\n",
    "                    bf_g_padded,\n",
    "                    bf_transform_mat,\n",
    "                    (wt_g_padded.shape[1], wt_g_padded.shape[0]),\n",
    "                )\n",
    "\n",
    "                # This hack is done to reduce the total contrast in the resulting image\n",
    "                # Otherwise, the 0s make it hard to see\n",
    "\n",
    "                bf_g_padded_warped[bf_g_padded_warped <= np.amin(bf_g_padded)] = (\n",
    "                    np.mean(bf_g_padded)\n",
    "                )\n",
    "\n",
    "                bf_g_padded_warped = norm_image(bf_g_padded_warped, False)\n",
    "                bf_warped_video.append(bf_g_padded_warped)\n",
    "\n",
    "        # tifffile.imwrite(\n",
    "        # output_path + Path(irm_path).stem + f\"_aligned_{frame_n}.tif\",\n",
    "        # irm_g_padded_warped_cropped,\n",
    "\n",
    "        # metadata=irm_metadata,\n",
    "\n",
    "        # )  # save irm image without the padding\n",
    "        # plt.imshow(irm_g_padded, alpha=0.5)\n",
    "        # plt.imshow(bf_g_padded_warped, alpha=0.5, cmap=\"Blues\")\n",
    "\n",
    "    if align_brightfield:\n",
    "        stacked_video = np.stack(\n",
    "            [wt_video, irm_warped_video, bf_warped_video], axis=1\n",
    "        )  # Save stacked g and irm image\n",
    "\n",
    "    else:\n",
    "\n",
    "        stacked_video = np.stack(\n",
    "            [wt_video, irm_warped_video], axis=1\n",
    "        )  # Save stacked g and irm image\n",
    "\n",
    "    tifffile.imwrite(\n",
    "        output_path + Path(wt_path).stem + \"_multichannel_aligned.tif\",\n",
    "        np.float32(stacked_video),\n",
    "        imagej=True,\n",
    "        metadata={\n",
    "            \"Composite mode\": \"composite\",  # This is what was needed for fiji to open it merged\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # plt.imshow(wt_g)\n",
    "\n",
    "    # delete padded files\n",
    "\n",
    "    # os.remove(output_path + padded_irm_filename)\n",
    "\n",
    "    # os.remove(output_path + padded_wt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1b09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41b578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ImageAligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
