{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import lumicks\n",
    "import lumicks.pylake as lk\n",
    "\n",
    "# %matplotlib inline\n",
    "from skimage.transform import rescale\n",
    "import tifffile\n",
    "import os\n",
    "from cv2 import warpAffine, invertAffineTransform\n",
    "from pathlib import Path\n",
    "from cv2 import estimateAffine2D, estimateAffinePartial2D\n",
    "from picasso import io, postprocess\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import argparse\n",
    "import itertools\n",
    "import math\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def norm_image(image, inverse=False):\n",
    "    amin = image.min()\n",
    "    amax = image.max()\n",
    "    if inverse:\n",
    "        return 1 - (image - amin) / (amax - amin)\n",
    "    else:\n",
    "        return (image - amin) / (amax - amin)\n",
    "\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664645c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(\n",
    "\n",
    "    description='\"Scripts to align various channels based on reference beads.\"',\n",
    "    epilog=\"\"\" \"\"\",\n",
    ")\n",
    "parser.add_argument(\"wt_file\", help=\"WT tif file\")\n",
    "parser.add_argument(\"irm_file\", help=\"IRM tif file\")\n",
    "parser.add_argument(    \"-o\",  \"--output-directory\",    default=\"output\",help=\"Output directory. Default=output/\",)\n",
    "parser.add_argument(\"-m\", \"--transform-matrix\", help=\"Previously calculated matrix in .json format\")\n",
    "parser.add_argument(\"-f\", \"--fit_method\", default=\"lq\", help=\"Fit method for picasso.  Default=lq\")\n",
    "parser.add_argument(\"-b\", \"--box_size\", default=21, help=\"Box sized for picasso. Default=21\")\n",
    "parser.add_argument(\"-g\",\"--min_gradient\",default=70000,help=\"Minimum gradient for picasso. Default=70000\",)\n",
    "parser.add_argument(\"-e\",\"--max_pos_error\",default=3.5,help=\"Maximum standard dev accepted for x and y position of spots. Default=3.5\",)\n",
    "parser.add_argument(\"-p\", \"--max_photons\", help=\"Maximum number of photons for spots.\")\n",
    "args = parser.parse_args()\n",
    "irm_path = args.irm_file\n",
    "wt_path = args.wt_file\n",
    "output_path = (args.output_directory + \"/\")  # The trailing slash is in case it wasn't added by the user\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to test without arguments\n",
    "\n",
    "\n",
    "# Reference images\n",
    "\n",
    "# irm_path = \"data/2025-07-30 data for new matrix/20240813-141353_IRM.tif\"\n",
    "# wt_path = \"data/2025-07-30 data for new matrix/20240813-141353_WT.tif\"\n",
    "# bright_path = \"data/2025-07-30 data for new matrix/20240813-141353_Bright-field.tif\"\n",
    "\n",
    "\n",
    "# Reference images\n",
    "\n",
    "irm_path = \"data/2025-07-30_calibration_data/20250730-084341.4912532_IRM.tiff\"\n",
    "wt_path = \"data/2025-07-30_calibration_data/20250730-084341.8961044_WT.tiff\"\n",
    "# bright_path = \"data/2025-07-30 data for new matrix/20240813-140703_Bright-field.tif\"\n",
    "\n",
    "output_path = \"data/2025-07-30_calibration_data/better_matrix/\"\n",
    "use_existing_matrix = False\n",
    "align_brightfield = False\n",
    "\n",
    "bf_transform_matrix_file = \"bf_transform_matrix.json\"\n",
    "transform_matrix_file = \"transform_matrix.json\"\n",
    "max_photons_exists = False\n",
    "max_photons = 800000\n",
    "min_gradient_irm = 20000\n",
    "min_gradient_wt = 20000\n",
    "box_size = 9\n",
    "fit_method = \"lq\"\n",
    "max_pos_error = 50\n",
    "\n",
    "box_size_bf = 21\n",
    "min_gradient_bf = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed50d15",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Check if the directory already exists\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if irm_path.endswith(\".tiff\"):\n",
    "\n",
    "    print(f\"renaming {irm_path} to .tif\")\n",
    "\n",
    "    os.rename(irm_path, irm_path[:-1])\n",
    "\n",
    "    irm_path = irm_path[:-1]\n",
    "\n",
    "if wt_path.endswith(\".tiff\"):\n",
    "\n",
    "    print(f\"renaming {wt_path} to .tif\")\n",
    "\n",
    "    os.rename(wt_path, wt_path[:-1])\n",
    "\n",
    "    wt_path = wt_path[:-1]\n",
    "\n",
    "\n",
    "if bright_path.endswith(\".tiff\"):\n",
    "\n",
    "    print(f\"renaming {bright_path} to .tif\")\n",
    "\n",
    "    os.rename(bright_path, bright_path[:-1])\n",
    "\n",
    "    bright_path = bright_path[:-1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322b226",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "irm = lk.ImageStack(irm_path)  # Loading a stack.\n",
    "wt = lk.ImageStack(wt_path)  # Loading a stack.\n",
    "\n",
    "if align_brightfield:\n",
    "    bright_file = lk.ImageStack(bright_path)\n",
    "    bright_g = bright_file.get_image(channel=\"green\")\n",
    "    bright_metadata = bright_file._tiff_image_metadata()\n",
    "\n",
    "wt.export_tiff(\n",
    "    output_path + Path(wt_path).stem + \"_aligned.tif\"\n",
    ")  # Save aligned wt stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c011acc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Get channels\n",
    "wt_g = wt.get_image(channel=\"green\")\n",
    "\n",
    "plt.imsave(output_path + Path(wt_path).stem + \"_wtG.tiff\", wt_g)\n",
    "\n",
    "# wt_r = wt.get_image(channel='red')  #not really used\n",
    "# wt_b = wt.get_image(channel='blue') #not really used\n",
    "irm_g = irm.get_image()\n",
    "plt.imshow(irm_g, alpha=0.3, cmap=\"Blues\")\n",
    "if align_brightfield:\n",
    "    plt.imshow(bright_g, alpha=0.3, cmap=\"Greens\")\n",
    "plt.imshow(wt_g, alpha=0.3, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe046734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get region of interest data\n",
    "\n",
    "# wt_metadata = wt._tiff_image_metadata()\n",
    "# wt_roi = wt_metadata[\"Alignment region of interest (x, y, width, height)\"]\n",
    "# print(wt_roi)\n",
    "\n",
    "wt_metadata = wt._tiff_image_metadata()\n",
    "wt_roi = wt_metadata[\"Region of interest (x, y, width, height)\"]\n",
    "print(wt_roi)\n",
    "\n",
    "irm_metadata = irm._tiff_image_metadata()\n",
    "irm_roi = irm_metadata[\n",
    "    \"Region of interest (x, y, width, height)\"\n",
    "]  # This is different because the wt was prexviously aligned I think. Can this cause issues?\n",
    "print(irm_roi)\n",
    "if align_brightfield:\n",
    "    bright_roi = bright_metadata[\n",
    "        \"Region of interest (x, y, width, height)\"\n",
    "    ]  # This is different because the wt was prexviously aligned I think. Can this cause issues?\n",
    "    print(bright_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dce4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "# Pad both images to region of interest\n",
    "padded_wt_filename = Path(wt_path).stem + \"_padded.tif\"\n",
    "wt_g_padded = np.pad(wt_g, [(int(wt_roi[1]), 0), (int(wt_roi[0]), 0)])\n",
    "# wt_g_padded = wt_g\n",
    "tifffile.imwrite(output_path + padded_wt_filename, wt_g_padded)\n",
    "\n",
    "padded_irm_filename = Path(irm_path).stem + \"_padded.tif\"\n",
    "irm_g_padded = np.pad(irm_g, [(int(irm_roi[1]), 0), (int(irm_roi[0]), 0)])\n",
    "# irm_g_padded = irm_g\n",
    "tifffile.imwrite(output_path + padded_irm_filename, irm_g_padded)\n",
    "\n",
    "if align_brightfield:\n",
    "\n",
    "    padded_bright_filename = Path(bright_path).stem + \"_padded.tif\"\n",
    "\n",
    "    bright_g_padded = np.pad(\n",
    "        bright_g, [(int(bright_roi[1]), 0), (int(bright_roi[0]), 0)]\n",
    "    )\n",
    "\n",
    "    # irm_g_padded = irm_g\n",
    "\n",
    "    # irm_g_padded = np.pad(irm_g, [(int(wt_roi[0]), 0), (int(wt_roi[1]), 0)])\n",
    "\n",
    "    # irm_g_padded = np.pad(irm_g_padded, [(int(wt_roi[0]), 0), (int(wt_roi[1]), 0)])\n",
    "\n",
    "    tifffile.imwrite(output_path + padded_bright_filename, bright_g_padded)\n",
    "\n",
    "\n",
    "# plt.imshow(bright_g_padded, alpha=0.5)\n",
    "\n",
    "\n",
    "ax1.imshow(wt_g_padded, alpha=0.5)\n",
    "ax1.set_xlim(wt_roi[0], wt_roi[0] + wt_roi[2])\n",
    "ax1.set_ylim(wt_roi[1], wt_roi[1] + wt_roi[3])\n",
    "\n",
    "# ax1.imshow(irm_g_padded, alpha=0.5)\n",
    "# ax1.set_xlim(irm_roi[0], irm_roi[0] + irm_roi[2])\n",
    "# ax1.set_ylim(irm_roi[1], irm_roi[1] + irm_roi[3])\n",
    "\n",
    "\n",
    "# ax1.imshow(bright_g_padded, alpha=0.5)\n",
    "# ax1.set_xlim(bright_roi[0], bright_roi[0] + bright_roi[2])\n",
    "# ax1.set_ylim(bright_roi[1], bright_roi[1] + bright_roi[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b654c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mat = []  # set to empty to check afterwards if I have a matrix\n",
    "bf_transform_mat = []\n",
    "if use_existing_matrix:  # If I have provided a matrix, use that\n",
    "    with open(transform_matrix_file, \"r\") as read_file:\n",
    "        decodedArray = json.load(read_file)\n",
    "        transform_mat = np.asarray(decodedArray[\"transform_matrix\"])\n",
    "        print(transform_mat)\n",
    "        rmsd = decodedArray[\"rmsd\"]\n",
    "    if align_brightfield:\n",
    "        with open(bf_transform_matrix_file, \"r\") as read_file:\n",
    "            decodedArray = json.load(read_file)\n",
    "            bf_transform_mat = np.asarray(decodedArray[\"transform_matrix\"])\n",
    "            print(bf_transform_mat)\n",
    "            rmsd = decodedArray[\"rmsd\"]\n",
    "else:  # if matrix wasnt provided, calculate it\n",
    "    print(\"Running localize\")\n",
    "    run_string = (\n",
    "        \"python -m picasso localize \"\n",
    "        + output_path\n",
    "        + padded_wt_filename\n",
    "        + \" --fit-method \"\n",
    "        + fit_method\n",
    "        + \" -b \"\n",
    "        + str(box_size)\n",
    "        + \" --gradient \"\n",
    "        + str(min_gradient_wt)\n",
    "    )\n",
    "    subprocess.run(run_string)\n",
    "\n",
    "    run_string = (\n",
    "        \"python -m picasso localize \"\n",
    "        + output_path\n",
    "        + padded_irm_filename\n",
    "        + \" --fit-method \"\n",
    "        + fit_method\n",
    "        + \" -b \"\n",
    "        + str(box_size)\n",
    "        + \" --gradient \"\n",
    "        + str(min_gradient_irm)\n",
    "    )\n",
    "    subprocess.run(run_string)\n",
    "\n",
    "    if align_brightfield:\n",
    "        run_string = (\n",
    "            \"python -m picasso localize \"\n",
    "            + output_path\n",
    "            + padded_bright_filename\n",
    "            + \" --fit-method \"\n",
    "            + fit_method\n",
    "            + \" -b \"\n",
    "            + str(box_size_bf)\n",
    "            + \" --gradient \"\n",
    "            + str(min_gradient_bf)\n",
    "        )\n",
    "    subprocess.run(run_string)\n",
    "    #!python -m picasso localize {output_path}wt_padded.tif --fit-method $args.fit_method -b  $args.box_size --gradient $args.min_gradient\n",
    "    #!python -m picasso localize {output_path}irm_padded.tif --fit-method $args.fit_method -b $args.box_size --gradient $args.min_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new Matrix\n",
    "if not use_existing_matrix:\n",
    "\n",
    "    # These parameters are for filtering based on position\n",
    "    irm_min_x = 0  # 370\n",
    "    irm_min_y = 0  # 392\n",
    "    irm_max_x = 100000000\n",
    "    irm_max_y = 100000000\n",
    "\n",
    "    wt_min_x = 0\n",
    "    wt_min_y = 0\n",
    "    wt_max_x = 100000000\n",
    "    wt_max_y = 100000000\n",
    "    max_pos_error = 50\n",
    "    min_photons = 42000\n",
    "    irm_locs_path = output_path + Path(padded_irm_filename).stem + \"_locs.hdf5\"\n",
    "\n",
    "    irm_locs, irm_info = io.load_locs(irm_locs_path)\n",
    "\n",
    "    wt_locs_path = output_path + Path(padded_wt_filename).stem + \"_locs.hdf5\"\n",
    "\n",
    "    wt_locs, wt_info = io.load_locs(wt_locs_path)\n",
    "\n",
    "    wt_locs = wt_locs[wt_locs[\"sx\"] < max_pos_error]\n",
    "\n",
    "    wt_locs = wt_locs[wt_locs[\"sy\"] < max_pos_error]\n",
    "\n",
    "    irm_locs = irm_locs[irm_locs[\"sx\"] < max_pos_error]\n",
    "\n",
    "    irm_locs = irm_locs[irm_locs[\"sy\"] < max_pos_error]\n",
    "\n",
    "    irm_locs = irm_locs[irm_locs[\"x\"] > irm_min_x]\n",
    "    irm_locs = irm_locs[irm_locs[\"y\"] > irm_min_y]\n",
    "    irm_locs = irm_locs[irm_locs[\"x\"] < irm_max_x]\n",
    "    irm_locs = irm_locs[irm_locs[\"y\"] < irm_max_y]\n",
    "\n",
    "    wt_locs = wt_locs[wt_locs[\"x\"] > wt_min_x]\n",
    "    wt_locs = wt_locs[wt_locs[\"y\"] > wt_min_y]\n",
    "    wt_locs = wt_locs[wt_locs[\"x\"] < wt_max_x]\n",
    "    wt_locs = wt_locs[wt_locs[\"y\"] < wt_max_y]\n",
    "\n",
    "    if max_photons_exists:\n",
    "\n",
    "        wt_locs = wt_locs[wt_locs[\"photons\"] < max_photons]\n",
    "\n",
    "        irm_locs = irm_locs[irm_locs[\"photons\"] < max_photons]\n",
    "\n",
    "    wt_locs = wt_locs[wt_locs[\"photons\"] > min_photons]\n",
    "    irm_locs = irm_locs[irm_locs[\"photons\"] > min_photons]\n",
    "\n",
    "    wt_locs_xy = wt_locs[[\"x\", \"y\"]].copy()\n",
    "\n",
    "    irm_locs_xy = irm_locs[[\"x\", \"y\"]].copy()\n",
    "    # plt.scatter(*zip(*irm_locs_xy), s=5)\n",
    "    wt_locs_xy = np.vstack([wt_locs_xy[item] for item in [\"x\", \"y\"]]).T.astype(\n",
    "        np.int64\n",
    "    )  # Parse to numpy array:\n",
    "\n",
    "    irm_locs_xy = np.vstack([irm_locs_xy[item] for item in [\"x\", \"y\"]]).T.astype(\n",
    "        np.int64\n",
    "    )\n",
    "\n",
    "    ###\n",
    "\n",
    "    wt_locs_xy = wt_locs_xy[\n",
    "        np.lexsort((wt_locs_xy[:, 1], wt_locs_xy[:, 0]))\n",
    "    ]  # Sort the points in case they are in different orders\n",
    "\n",
    "    irm_locs_xy = irm_locs_xy[np.lexsort((irm_locs_xy[:, 1], irm_locs_xy[:, 0]))]\n",
    "\n",
    "    ###\n",
    "\n",
    "    # print(irm_locs_xy)\n",
    "\n",
    "    # print(wt_locs_xy)\n",
    "\n",
    "    # plt.scatter(*zip(*wt_locs_xy), s=5)\n",
    "\n",
    "    # plt.scatter(*zip(*irm_locs_xy), s=5)\n",
    "\n",
    "    if len(wt_locs_xy) != len(\n",
    "        irm_locs_xy\n",
    "    ):  # If number of points is different after filtering give an error an exit\n",
    "        print(\n",
    "            \"Different number of spots after filtering (wt: \"\n",
    "            + str(len(wt_locs_xy))\n",
    "            + \" vs irm: \"\n",
    "            + str(len(irm_locs_xy))\n",
    "            + \"). Calculation can't continue\"\n",
    "        )\n",
    "\n",
    "        print(\"Check your filtering settings\")\n",
    "\n",
    "    else:  # If number of points is the same, calculate affine transform\n",
    "        print(\n",
    "            \"Number of spots after filtering (wt: \"\n",
    "            + str(len(wt_locs_xy))\n",
    "            + \" vs irm: \"\n",
    "            + str(len(irm_locs_xy))\n",
    "            + \").\"\n",
    "        )\n",
    "\n",
    "        affine_transform = estimateAffine2D(irm_locs_xy, wt_locs_xy)\n",
    "\n",
    "        transform_mat = affine_transform[0]\n",
    "        print(transform_mat)\n",
    "\n",
    "        # Manually affine transform the points to output alignment plot\n",
    "\n",
    "        transform_mat_for_points = np.vstack(\n",
    "            [transform_mat, (0, 0, 1)]\n",
    "        )  # have to add this row for affine transform\n",
    "\n",
    "        warped_irm_locs = []\n",
    "\n",
    "        for point in irm_locs_xy:\n",
    "\n",
    "            new_point = (\n",
    "                point[0],\n",
    "                point[1],\n",
    "                1,\n",
    "            )  # need to add a 1 at the end of the point for affine transform\n",
    "\n",
    "            # print(new_point)\n",
    "\n",
    "            transformed_point = np.matmul(\n",
    "                transform_mat_for_points, new_point\n",
    "            )  # do the transformation\n",
    "\n",
    "            new_point = (\n",
    "                transformed_point[0],\n",
    "                transformed_point[1],\n",
    "            )  # transformed point\n",
    "\n",
    "            warped_irm_locs.append(new_point)\n",
    "\n",
    "        warped_irm_locs = np.array(warped_irm_locs)\n",
    "\n",
    "        wt_locs_xy_sorted = wt_locs_xy[\n",
    "            np.lexsort((wt_locs_xy[:, 1], wt_locs_xy[:, 0]))\n",
    "        ]  # Sort the points in case they are in different orders\n",
    "\n",
    "        warped_irm_locs_sorted = warped_irm_locs[\n",
    "            np.lexsort((warped_irm_locs[:, 1], warped_irm_locs[:, 0]))\n",
    "        ]\n",
    "\n",
    "        rmsd = np.sqrt(\n",
    "            ((((wt_locs_xy_sorted - warped_irm_locs_sorted) ** 2)) * 3).mean()\n",
    "        )  # calculate RMSD\n",
    "\n",
    "        numpyData = {\n",
    "            \"transform_matrix\": transform_mat,\n",
    "            \"rmsd\": rmsd,\n",
    "        }  # Write transform matrix and rmsd to file\n",
    "\n",
    "        with open(output_path + \"transform_matrix.json\", \"w\") as write_file:\n",
    "\n",
    "            json.dump(numpyData, write_file, cls=NumpyArrayEncoder)\n",
    "\n",
    "        # Remove files created during localization\n",
    "\n",
    "        # os.remove(wt_locs_path)\n",
    "\n",
    "        # os.remove(irm_locs_path)\n",
    "\n",
    "        # os.remove(output_path + Path(wt_locs_path).stem + \".yaml\")\n",
    "\n",
    "        # os.remove(output_path + Path(irm_locs_path).stem + \".yaml\")\n",
    "\n",
    "        # Plot aligned points\n",
    "\n",
    "        # plt.scatter(*zip(*wt_locs_xy), s=5)\n",
    "\n",
    "        # plt.scatter(*zip(*warped_irm_locs), s=5)\n",
    "\n",
    "        # plt.savefig(output_path + \"aligned_points.png\")\n",
    "\n",
    "        # Now do the same with brightfield\n",
    "\n",
    "        if align_brightfield:\n",
    "            # These parameters are for filtering based on position\n",
    "\n",
    "            bf_min_x = 509  # 28\n",
    "            bf_min_y = 421  # 745\n",
    "            bf_max_x = bf_min_x + 222\n",
    "            bf_max_y = bf_min_y + 204\n",
    "\n",
    "            bf_locs_path = (\n",
    "                output_path + Path(padded_bright_filename).stem + \"_locs.hdf5\"\n",
    "            )\n",
    "            bf_locs, bf_info = io.load_locs(bf_locs_path)\n",
    "            # bf_locs = bf_locs[bf_locs[\"sx\"] < max_pos_error]\n",
    "            # bf_locs = bf_locs[bf_locs[\"sy\"] < max_pos_error]\n",
    "            bf_locs = bf_locs[bf_locs[\"x\"] > bf_min_x]\n",
    "            bf_locs = bf_locs[bf_locs[\"y\"] > bf_min_y]\n",
    "            bf_locs = bf_locs[bf_locs[\"x\"] < bf_max_x]\n",
    "            bf_locs = bf_locs[bf_locs[\"y\"] < bf_max_y]\n",
    "\n",
    "            if max_photons_exists:\n",
    "                bf_locs = bf_locs[bf_locs[\"photons\"] < max_photons]\n",
    "\n",
    "            bf_locs_xy = bf_locs[[\"x\", \"y\"]].copy()\n",
    "\n",
    "            bf_locs_xy = np.vstack([bf_locs_xy[item] for item in [\"x\", \"y\"]]).T.astype(\n",
    "                np.int64\n",
    "            )  # Parse to numpy array:\n",
    "\n",
    "            ###\n",
    "            bf_locs_xy = bf_locs_xy[\n",
    "                np.lexsort((bf_locs_xy[:, 1], bf_locs_xy[:, 0]))\n",
    "            ]  # Sort the points in case they are in different orders\n",
    "\n",
    "            ###\n",
    "            # print(irm_locs_xy)\n",
    "            # print(wt_locs_xy)\n",
    "            # plt.scatter(*zip(*wt_locs_xy), s=5)\n",
    "            # plt.scatter(*zip(*irm_locs_xy), s=5)\n",
    "\n",
    "            if len(wt_locs_xy) != len(\n",
    "                bf_locs_xy\n",
    "            ):  # If number of points is different after filtering give an error an exit\n",
    "                print(\n",
    "                    \"Different number of spots after filtering (wt: \"\n",
    "                    + str(len(wt_locs_xy))\n",
    "                    + \" vs bf: \"\n",
    "                    + str(len(bf_locs_xy))\n",
    "                    + \"). Calculation can't continue\"\n",
    "                )\n",
    "                print(\"Check your filtering settings\")\n",
    "            else:\n",
    "                # If number of points is the same, calculate affine transform\n",
    "                print(\n",
    "                    \"Number of spots found: (wt: \"\n",
    "                    + str(len(wt_locs_xy))\n",
    "                    + \" vs bf: \"\n",
    "                    + str(len(bf_locs_xy))\n",
    "                    + \").\"\n",
    "                )\n",
    "                affine_transform = estimateAffine2D(bf_locs_xy, wt_locs_xy)\n",
    "                bf_transform_mat = affine_transform[0]\n",
    "                print(bf_transform_mat)\n",
    "                # Manually affine transform the points to output alignment plot\n",
    "\n",
    "                bf_transform_mat_for_points = np.vstack(\n",
    "                    [bf_transform_mat, (0, 0, 1)]\n",
    "                )  # have to add this row for affine transform\n",
    "\n",
    "                warped_bf_locs = []\n",
    "\n",
    "                for point in bf_locs_xy:\n",
    "                    new_point = (\n",
    "                        point[0],\n",
    "                        point[1],\n",
    "                        1,\n",
    "                    )  # need to add a 1 at the end of the point for affine transform\n",
    "                    # print(new_point)\n",
    "                    transformed_point = np.matmul(\n",
    "                        bf_transform_mat_for_points, new_point\n",
    "                    )  # do the transformation\n",
    "                    new_point = (\n",
    "                        transformed_point[0],\n",
    "                        transformed_point[1],\n",
    "                    )  # transformed point\n",
    "\n",
    "                    warped_bf_locs.append(new_point)\n",
    "\n",
    "                warped_bf_locs = np.array(warped_bf_locs)\n",
    "\n",
    "                warped_bf_locs_sorted = warped_bf_locs[\n",
    "                    np.lexsort((warped_bf_locs[:, 1], warped_bf_locs[:, 0]))\n",
    "                ]\n",
    "                rmsd = np.sqrt(\n",
    "                    ((((wt_locs_xy_sorted - warped_bf_locs_sorted) ** 2)) * 3).mean()\n",
    "                )  # calculate RMSD\n",
    "\n",
    "                numpyData = {\n",
    "                    \"transform_matrix\": bf_transform_mat,\n",
    "                    \"rmsd\": rmsd,\n",
    "                }  # Write transform matrix and rmsd to file\n",
    "                with open(output_path + \"bf_transform_matrix.json\", \"w\") as write_file:\n",
    "                    json.dump(numpyData, write_file, cls=NumpyArrayEncoder)\n",
    "\n",
    "                # Remove files created during localization\n",
    "                # os.remove(wt_locs_path)\n",
    "                # os.remove(irm_locs_path)\n",
    "                # os.remove(output_path + Path(wt_locs_path).stem + \".yaml\")\n",
    "                # os.remove(output_path + Path(irm_locs_path).stem + \".yaml\")\n",
    "                # Plot aligned points\n",
    "                plt.scatter(*zip(*wt_locs_xy), s=9)\n",
    "                plt.scatter(*zip(*warped_irm_locs), s=9)\n",
    "                plt.scatter(*zip(*warped_bf_locs), s=9)\n",
    "                plt.savefig(output_path + \"aligned_points.png\")\n",
    "        else:\n",
    "            plt.scatter(*zip(*wt_locs_xy), s=5)\n",
    "            plt.scatter(*zip(*warped_irm_locs), s=5)\n",
    "            plt.savefig(output_path + \"aligned_points.png\")\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Not calculating new matrix. Nothing run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22414c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align and save\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "if len(transform_mat != 0):  # If I have a matrix either from file or calculated\n",
    "\n",
    "    irm_g_padded_warped = warpAffine(\n",
    "        irm_g_padded, transform_mat, (wt_g_padded.shape[1], wt_g_padded.shape[0])\n",
    "    )\n",
    "\n",
    "    # irm_g_padded_warped = np.pad(irm_g_padded_warped, [(int(wt_roi[0]), 0), (int(wt_roi[1]), 0)] )\n",
    "\n",
    "    # This hack is done to reduce the total contrast in the resulting image\n",
    "    # Otherwise, the 0s make it hard to see\n",
    "    irm_g_padded_warped[irm_g_padded_warped <= np.amin(irm_g_padded)] = np.mean(\n",
    "        irm_g_padded\n",
    "    )\n",
    "\n",
    "    irm_g_padded_warped = norm_image(irm_g_padded_warped)\n",
    "    wt_g_padded = norm_image(wt_g_padded)\n",
    "\n",
    "    # irm_g_padded_warped_cropped = irm_g_padded_warped[#\n",
    "    #    0 : wt_g_padded.shape[0], 0 : wt_g_padded.shape[1]\n",
    "    # ]  # crop to size of wt\n",
    "\n",
    "    tifffile.imwrite(\n",
    "        output_path + Path(irm_path).stem + \"_aligned.tif\",\n",
    "        irm_g_padded_warped,\n",
    "        metadata=irm_metadata,\n",
    "    )  # save irm image without the padding\n",
    "\n",
    "    # plt.imshow(irm_g_padded, alpha=0.5)\n",
    "\n",
    "    # plt.imshow(irm_g_padded_warped_cropped, alpha=0.5)\n",
    "\n",
    "    if align_brightfield:  # If a brightfield file was provided align that too\n",
    "\n",
    "        if len(bf_transform_mat) != 0:\n",
    "\n",
    "            bright_g_padded_warped = warpAffine(\n",
    "                bright_g_padded,\n",
    "                bf_transform_mat,\n",
    "                (wt_g_padded.shape[1], wt_g_padded.shape[0]),\n",
    "            )\n",
    "\n",
    "            # This hack removes the 0s from the affine transform\n",
    "\n",
    "            # Otherwise, the 0s make it hard to see because of contrast\n",
    "\n",
    "            bright_g_padded_warped[bright_g_padded_warped <= np.amin(bright_g)] = (\n",
    "                np.mean(bright_g_padded)\n",
    "            )\n",
    "\n",
    "            # normalize\n",
    "\n",
    "            bright_g_padded_warped = norm_image(bright_g_padded_warped)\n",
    "\n",
    "            tifffile.imwrite(\n",
    "                output_path + Path(bright_path).stem + \"_aligned.tif\",\n",
    "                bright_g_padded_warped,\n",
    "                metadata=bright_metadata,\n",
    "            )  # save irm image without the padding\n",
    "\n",
    "            stacked_image = np.stack(\n",
    "                [wt_g_padded, irm_g_padded_warped, bright_g_padded_warped],\n",
    "                axis=0,\n",
    "            )  # Save stacked g and irm image\n",
    "            tifffile.imwrite(\n",
    "                output_path + Path(wt_path).stem + \"_multichannel_aligned.tif\",\n",
    "                np.float32(stacked_image),\n",
    "                imagej=True,\n",
    "                metadata={\n",
    "                    \"Composite mode\": \"composite\",  # This is what was needed for fiji to open it merged\n",
    "                },\n",
    "            )\n",
    "            ax1.imshow(wt_g_padded, alpha=0.5)\n",
    "            ax1.imshow(bright_g_padded_warped, alpha=0.5)\n",
    "            ax1.imshow(irm_g_padded_warped, alpha=0.5)\n",
    "            ax1.set_xlim(wt_roi[0], wt_roi[0] + wt_roi[2])\n",
    "            ax1.set_ylim(wt_roi[1], wt_roi[1] + wt_roi[3])\n",
    "\n",
    "        else:  # If no bf transform matrix\n",
    "\n",
    "            print(\"You also need to provide the brightfield alignment matrix\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        stacked_image = np.stack(\n",
    "            [wt_g_padded, irm_g_padded_warped], axis=0\n",
    "        )  # Save stacked g and irm image\n",
    "        tifffile.imwrite(\n",
    "            output_path + Path(wt_path).stem + \"_multichannel_aligned.tif\",\n",
    "            np.float32(stacked_image),\n",
    "            imagej=True,\n",
    "            metadata={\n",
    "                \"Composite mode\": \"composite\",  # This is what was needed for fiji to open it merged\n",
    "            },\n",
    "        )\n",
    "        # plt.imshow(bright_g_padded_warped, alpha=0.5)\n",
    "\n",
    "        ax1.imshow(wt_g_padded, alpha=0.5)\n",
    "\n",
    "        ax1.imshow(irm_g_padded_warped, alpha=0.5)\n",
    "        ax1.set_xlim(wt_roi[0], wt_roi[0] + wt_roi[2])\n",
    "        ax1.set_ylim(wt_roi[1], wt_roi[1] + wt_roi[3])\n",
    "\n",
    "    # plt.imshow(wt_g)\n",
    "\n",
    "    # delete padded files\n",
    "\n",
    "    # os.remove(output_path + padded_irm_filename)\n",
    "\n",
    "    # os.remove(output_path + padded_wt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "irm._src.close()  # need to close the file before deleting\n",
    "wt._src.close()  # need to close the file before deleting\n",
    "bright_file._src.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ImageAligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
